# Ignacio Salceda Rodríguez

Data Engineer and analytics-driven professional, currently working as a Data Engineer, with experience building data-intensive systems, analytical platforms, and decision-support solutions in both consulting and academic environments.

My work sits at the intersection of **data engineering, analytics, and applied machine learning**, with a strong focus on building systems that are understandable, scalable, and useful to real stakeholders.

---

## What I work on

I’m particularly interested in:
- End-to-end data systems: from ingestion and storage to analytics and decision-making  
- Data engineering patterns for real-world environments (batch, streaming, lakehouse)  
- Applied analytics and ML projects that connect data to business outcomes  

I care less about flashy demos and more about **clear data models, sound architecture, and reproducible workflows**.

---

## Selected Projects

### Retail Multi-Agent Analytics System
Designed and implemented a multi-agent system for enterprise data environments using **LangGraph and LangChain**, enabling dynamic SQL generation and document-enriched reasoning to answer complex business questions.  
The system simulates advanced analytics workflows by combining structured data access with contextual reasoning.

**Tech:** Python, SQL, LangGraph, LangChain, Docker

---

### Retail Data Architecture (Academic)
Architected an end-to-end **retail data system** (MySQL + Docker) focused on data and system architecture, modeling realistic enterprise entities (regions, stores, employees, products, inventory, sales) with strict integrity constraints.

Designed a **synthetic data generation architecture** in Python to simulate production-like data flows, ensuring logical consistency across entities.  
The system was explicitly structured to support the **onboarding and training of junior data profiles**, serving as a realistic environment for learning SQL, data modeling, and analytics.

**Tech:** MySQL, Docker, Python, Faker

---

### Lakehouse Data Platform (Team Project)
Collaborated on the development of a **lakehouse-style data platform** integrating MinIO, Kafka, Spark, Airflow, and Redis.  
Contributed to core development tasks within a team-defined architecture and took responsibility for **repository management, code structure, and integration workflows**.

**Tech:** Spark, Kafka, Airflow, MinIO, Redis, Python, Git

---

### Applied Analytics & MLOps Projects
- **Formula 1 Era-Agnostic Analysis:** Driver performance ranking across eras using standardized metrics, delivered via an interactive Streamlit app.  
- **TfL Near Real-Time Analytics:** Spark-based pipeline consuming the Transport for London API for crowding and delay analysis.  
- **Fraud Detection MLOps Pipeline:** Modular, production-ready ML pipeline with testing, CI/CD, and reproducibility at its core.

---

## Background

- **MSc Data Science & Business Analytics** – IE School of Science and Technology (GPA 3.7/4, Honors)  
- **3+ years in digital analytics and consulting**, delivering data-driven insights for multinational clients  
- Current **Data Engineer** working on data platforms and AI-enabled analytics systems  

---

## Tech Stack

**Languages:** Python, SQL, PySpark  
**Data & ML:** Spark, Kafka, Scikit-learn, MLlib, PyTorch, TensorFlow  
**Data Engineering:** Lakehouse architectures, ETL, Docker, Git, CI/CD  
**Analytics & BI:** Tableau, Streamlit, Google Analytics  

---

I treat repositories as **working systems**, not code dumps.  
If something is here, it’s because it taught me something worth keeping.
